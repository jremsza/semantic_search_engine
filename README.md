# Semantic Search System

A web-based semantic search engine for data science knowledge base with side-by-side comparison of TF-IDF baseline and semantic search models.

## Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Build the Baseline Model (Optional)
```bash
python wsl_scripts/build_baseline.py
```

This creates the TF-IDF baseline model files in the `models/` directory.

### 3. Start ChromaDB
**Command Prompt/PowerShell:**
```
docker-compose up -d
```

### 4. Launch Web App
**Command Prompt/PowerShell:**
```bash
streamlit run src/search_engine.py
```

### 5. Open Your Browser
Go to `http://localhost:8501`

## How to Use

1. **Type your question** in the search box (e.g., "What is a transformer?")
2. **Click Search** to find relevant documents
3. **View side-by-side results** comparing:
   - **Semantic Search** (left) - Using embeddings and ChromaDB
   - **Baseline TF-IDF** (right) - Using traditional term frequency-inverse document frequency
4. **Compare similarity scores** between both models

## Features

- ✅ **6,579 documents** from data science topics
- ✅ **Dual search models** - Semantic search and TF-IDF baseline
- ✅ **Side-by-side comparison** - Compare results from both models simultaneously
- ✅ **Similarity scores** - See relevance metrics for each result
- ✅ **Web interface** - No coding required
- ✅ **Model status indicators** - Check connection status for both models in the sidebar

## Requirements

### For Semantic Search:
- ChromaDB running via Docker (`docker-compose up -d`)
- Recomended: GPU for vector embeddings (generated by `wsl_scripts/embeddings.py`)

### For Baseline Model:
- TF-IDF model files in `models/` directory (generated by `wsl_scripts/build_baseline.py`)
- Requires `data/ds_corpus_clean.jsonl` to build the model

## Architecture

```
Streamlit Web App
├── Semantic Search → ChromaDB (Docker) with embeddings
└── Baseline Search → TF-IDF model files (local)
```

